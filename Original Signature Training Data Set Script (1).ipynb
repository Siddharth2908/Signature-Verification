{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "from matplotlib import pyplot as matplot\n",
    "%matplotlib inline\n",
    "import pandas as pandas\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "import cv2\n",
    "import os\n",
    "import ntpath\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import fnmatch\n",
    "\n",
    "data = []\n",
    "Filename = []\n",
    "Person = []\n",
    "Testdata = []\n",
    "TestFilename = []\n",
    "TestPerson = []\n",
    "\n",
    "\n",
    "def crop_image(img,tol=0):\n",
    "    mask = img>tol\n",
    "    return img[numpy.ix_(mask.any(1),mask.any(0))]\n",
    "def thinning(img):\n",
    "    #img = cropimage\n",
    "    size = numpy.size(img)\n",
    "    skel = numpy.zeros(img.shape,numpy.uint8)\n",
    "\n",
    "    ret,img = cv2.threshold(img,127,255,0)\n",
    "    element = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "    done = False\n",
    "\n",
    "    while( not done):\n",
    "        eroded = cv2.erode(img,element)\n",
    "        temp = cv2.dilate(eroded,element)\n",
    "        temp = cv2.subtract(img,temp)\n",
    "        skel = cv2.bitwise_or(skel,temp)\n",
    "        img = eroded.copy()\n",
    "\n",
    "        zeros = size - cv2.countNonZero(img)\n",
    "        if zeros==size:\n",
    "            done = True\n",
    "\n",
    "  #  plt.imshow(skel,'gray')\n",
    "   # plt.show()\n",
    "    return skel\n",
    "def coords(thinnedimage):\n",
    "    rows,cols=thinnedimage.shape\n",
    "    img_topleft=thinnedimage[0:int(rows/2),0:int(cols/2)]\n",
    "    img_topright=thinnedimage[int(rows/2)+1:rows,0:int(cols/2)]\n",
    "    img_bottomleft=thinnedimage[0:int(rows/2),int(cols/2)+1:cols]\n",
    "    img_bottomright=thinnedimage[int(rows/2)+1:rows,int(cols/2)+1:cols]\n",
    "    \n",
    "    topleft_x,topleft_y=COG(img_topleft)\n",
    "    topright_x,topright_y=COG(img_topright)\n",
    "    bottomleft_x,bottomleft_y=COG(img_bottomleft)\n",
    "    bottomright_x,bottomright_y=COG(img_bottomright)\n",
    "\n",
    "    return topleft_x,topleft_y,topright_x,topright_y,bottomleft_x,bottomleft_y,bottomright_x,bottomright_y\n",
    "\n",
    "def COG(img):\n",
    "    x_cor=0\n",
    "    xrun_sum=0\n",
    "    y_cor=0\n",
    "    yrun_sum=0\n",
    "    #print(img.shape)\n",
    "    for i in range(img.shape[0]):\n",
    "        x_cor+=sum(img[i])*i/255\n",
    "        xrun_sum+=sum(img[i])/255\n",
    "\n",
    "    for i in range(img.shape[1]):\n",
    "        y_cor+=sum(img[:,i])*i/255\n",
    "        yrun_sum+=sum(img[:,i])/255\n",
    "        #print(img.shape[1]) \n",
    "        if yrun_sum==0:\n",
    "            x_pos=0\n",
    "        else:\n",
    "            x_pos=y_cor/(yrun_sum)\n",
    "        if xrun_sum==0:\n",
    "            y_pos=0\n",
    "        else:\n",
    "            y_pos=x_cor/(xrun_sum)\n",
    "        \n",
    "   # print(x_pos)\n",
    "  #  print(y_pos)\n",
    "    \n",
    "    return (x_pos/img.shape[1],y_pos/img.shape[0])\n",
    "\n",
    "def tan_i(x):\n",
    "    #print(x)\n",
    "    if x[0]==0:\n",
    "        return 90\n",
    "    return math.degrees(math.atan(x[1]/x[0]))\n",
    "\n",
    "def tan(thinnedimage):\n",
    "    rows,cols=thinnedimage.shape\n",
    "    \n",
    "    img_tl1=thinnedimage[0:int(rows/2),0:int(cols/4)]\n",
    "    img_tl2=thinnedimage[0:int(rows/2),int(cols/4)+1:int(cols/2)]\n",
    "    \n",
    "    img_tr1=thinnedimage[0:int(rows/2),int(cols/2)+1:int(0.75*cols)]\n",
    "    img_tr2=thinnedimage[0:int(rows/2),int(0.75*cols)+1:cols]\n",
    "    \n",
    "    img_bl1=thinnedimage[int(rows/2)+1:rows,0:int(cols/4)]\n",
    "    img_bl2=thinnedimage[int(rows/2)+1:rows,int(cols/4)+1:int(cols/2)]\n",
    "    \n",
    "    img_br1=thinnedimage[int(rows/2)+1:rows,int(cols/2)+1:int(0.75*cols)]\n",
    "    img_br2=thinnedimage[int(rows/2)+1:rows,int(0.75*cols)+1:cols]\n",
    "    \n",
    "\n",
    "    #plt.imshow(timg,'gray')\n",
    "    #plt.show()\n",
    "    \n",
    "    tl1=tan_i(COG(img_tl1))\n",
    "    tl2=tan_i(COG(img_tl2))\n",
    "    tr1=tan_i(COG(img_tr1))\n",
    "    tr2=tan_i(COG(img_tr2))\n",
    "    bl1=tan_i(COG(img_bl1))\n",
    "    bl2=tan_i(COG(img_bl2))\n",
    "    br1=tan_i(COG(img_br1))\n",
    "    br2=tan_i(COG(img_br2))\n",
    "    \n",
    "    #plt.imshow(img_br1,'gray')\n",
    "    #plt.show()\n",
    "    #print(COG(img_br1))\n",
    "    return tl1,tl2,tr1,tr2,bl1,bl2,br1,br2\n",
    "\n",
    "def createfingerprint_Genuine(image):\n",
    "    aspect_ratio = 1.0*(image.shape[1]/image.shape[0])\n",
    "    ret,thresh1 = cv2.threshold(image,127,255,cv2.THRESH_BINARY)\n",
    "    ret,thresh2 = cv2.threshold(image,127,255,cv2.THRESH_BINARY_INV)\n",
    "    ret,thresh3 = cv2.threshold(image,127,255,cv2.THRESH_TRUNC)\n",
    "    ret,thresh4 = cv2.threshold(image,127,255,cv2.THRESH_TOZERO)\n",
    "    ret,thresh5 = cv2.threshold(image,127,255,cv2.THRESH_TOZERO_INV)\n",
    "    blur = cv2.GaussianBlur(thresh1,(5,5),0)\n",
    "    ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    image=numpy.invert(th3)\n",
    "    \n",
    "    cropimage=crop_image(image,tol=0)\n",
    "    area=cv2.countNonZero(cropimage)\n",
    "    area=cv2.countNonZero(cropimage)/(cropimage.shape[0]*cropimage.shape[1])\n",
    "\n",
    "    img1=numpy.invert(cropimage)\n",
    "    connectcomp=cv2.connectedComponents(img1)[0]\n",
    "\n",
    "    thinnedimage=thinning(cropimage)\n",
    "    #Thinning the image!\n",
    "\n",
    "    topleft_x,topleft_y,topright_x,topright_y,bottomleft_x,bottomleft_y,bottomright_x,bottomright_y=coords(thinnedimage)\n",
    "    tan_topleft_x, tan_topleft_y, tan_topright_x, tan_topright_y, tan_bottomleft_x, tan_bottomleft_y, tan_bottomright_x, tan_bottomright_y = tan(thinnedimage)\n",
    "    \n",
    "        #Extracting features\n",
    "\n",
    "    a=pandas.Series([area,connectcomp,topleft_x,topleft_y,topright_x,topright_y,bottomleft_x,bottomleft_y,bottomright_x,bottomright_y,tan_topleft_x, tan_topleft_y, tan_topright_x, tan_topright_y, tan_bottomleft_x, tan_bottomleft_y, tan_bottomright_x, tan_bottomright_y,aspect_ratio],index=\n",
    "                    [\"Norm_area\",\"connected_comps\",\"topleft_x\",\"topleft_y\",\"topright_x\",\"topright_y\",\"bottomleft_x\",\"bottomleft_y\",\"bottomright_x\",\"bottomright_y\",\"tan_topleft_x\", \"tan_topleft_y\", \"tan_topright_x\", \"tan_topright_y\", \"tan_bottomleft_x\", \"tan_bottomleft_y\", \"tan_bottomright_x\", \"tan_bottomright_y\",\"Aspect_Ratio\"])\n",
    "    data.append(a)\n",
    "\n",
    "def createfingerprint_Test(image):\n",
    "    aspect_ratio = 1.0*(image.shape[1]/image.shape[0])\n",
    "    ret,thresh1 = cv2.threshold(image,127,255,cv2.THRESH_BINARY)\n",
    "    ret,thresh2 = cv2.threshold(image,127,255,cv2.THRESH_BINARY_INV)\n",
    "    ret,thresh3 = cv2.threshold(image,127,255,cv2.THRESH_TRUNC)\n",
    "    ret,thresh4 = cv2.threshold(image,127,255,cv2.THRESH_TOZERO)\n",
    "    ret,thresh5 = cv2.threshold(image,127,255,cv2.THRESH_TOZERO_INV)\n",
    "    blur = cv2.GaussianBlur(thresh1,(5,5),0)\n",
    "    ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    image=numpy.invert(th3)\n",
    "    \n",
    "    cropimage=crop_image(image,tol=0)\n",
    "    area=cv2.countNonZero(cropimage)\n",
    "    area=cv2.countNonZero(cropimage)/(cropimage.shape[0]*cropimage.shape[1])\n",
    "\n",
    "    img1=numpy.invert(cropimage)\n",
    "    connectcomp=cv2.connectedComponents(img1)[0]\n",
    "\n",
    "    thinnedimage=thinning(cropimage)\n",
    "    #Thinning the image!\n",
    "\n",
    "    topleft_x,topleft_y,topright_x,topright_y,bottomleft_x,bottomleft_y,bottomright_x,bottomright_y=coords(thinnedimage)\n",
    "    tan_topleft_x, tan_topleft_y, tan_topright_x, tan_topright_y, tan_bottomleft_x, tan_bottomleft_y, tan_bottomright_x, tan_bottomright_y = tan(thinnedimage)\n",
    "    \n",
    "        #Extracting features\n",
    "\n",
    "    b=pandas.Series([area,connectcomp,topleft_x,topleft_y,topright_x,topright_y,bottomleft_x,bottomleft_y,bottomright_x,bottomright_y,tan_topleft_x, tan_topleft_y, tan_topright_x, tan_topright_y, tan_bottomleft_x, tan_bottomleft_y, tan_bottomright_x, tan_bottomright_y,aspect_ratio],index=\n",
    "                    [\"Norm_area\",\"connected_comps\",\"topleft_x\",\"topleft_y\",\"topright_x\",\"topright_y\",\"bottomleft_x\",\"bottomleft_y\",\"bottomright_x\",\"bottomright_y\",\"tan_topleft_x\", \"tan_topleft_y\", \"tan_topright_x\", \"tan_topright_y\", \"tan_bottomleft_x\", \"tan_bottomleft_y\", \"tan_bottomright_x\", \"tan_bottomright_y\",\"Aspect_Ratio\"])\n",
    "    Testdata.append(b)    \n",
    "    \n",
    "\n",
    "def create_training_Genuine_dataset(m):\n",
    "    os.chdir(Genuinedir)\n",
    "    filecount = len(fnmatch.filter(os.listdir(), '*.png'))\n",
    "    n = int(filecount/m)\n",
    "    for j in range(1,m+1):\n",
    "        for i in range(1,n+1):\n",
    "            path = f\"D:\\\\Data Science\\\\Python\\\\Signature Verification\\\\Training Data\\\\Train_Genuine\\\\00{j}_{i}.png\"\n",
    "            fn = ntpath.basename(path)\n",
    "            Filename.append(fn)\n",
    "            tn = j\n",
    "            Person.append(tn)\n",
    "            image = cv2.imread(path,0)\n",
    "            createfingerprint_Genuine(image)\n",
    "            Original_Signature_Table=pandas.DataFrame(data)\n",
    "            Original_Cosine = pandas.DataFrame(cosine_similarity(Original_Signature_Table), index = None)\n",
    "            \n",
    "    Original_Signature_Table['Filename'] = Filename\n",
    "    Original_Cosine['Filename'] = Filename\n",
    "    Trainingdatacol = Original_Signature_Table.columns.tolist()\n",
    "    Trainingdatacol = Trainingdatacol[-1:]+Trainingdatacol[:-1]\n",
    "    Original_Signature_Table = Original_Signature_Table[Trainingdatacol]\n",
    "    Original_Signature_Table['Person'] = Person\n",
    "    Trainingdatacol = Original_Signature_Table.columns.tolist()\n",
    "    Trainingdatacol = Trainingdatacol[-1:]+Trainingdatacol[:-1]\n",
    "    Original_Signature_Table = Original_Signature_Table[Trainingdatacol]\n",
    "    Original_Signature_Table['Category'] = \"Genuine\"\n",
    "    Cosinecolumns = Original_Cosine.columns.tolist()\n",
    "    Cosinecolumns = Cosinecolumns[-1:]+Cosinecolumns[:-1]\n",
    "    Original_Cosine = Original_Cosine[Cosinecolumns]\n",
    "    #Original_Signature_Table = pandas.concat([Original_Signature_Table,Cosine],axis = 1)\n",
    "    Original_Signature_Table.to_csv('Training.csv', index = False)\n",
    "    Original_Cosine.to_csv('Cosine_Training.csv', index = False)\n",
    "    Summary_Table = pandas.DataFrame(Original_Signature_Table.describe()).T\n",
    "    Summary_Table.to_csv('Training_Summary.csv', index = False)\n",
    "    Original_Signature_Table\n",
    "    Original_Cosine\n",
    "    print('Preprocessing of Training Data Completed')\n",
    "    \n",
    "def create_test_dataset(x):\n",
    "    os.chdir(Testdir)\n",
    "    Testcount = len(fnmatch.filter(os.listdir(), '*.png'))\n",
    "    y = int(Testcount/x)\n",
    "    for j in range(1,x+1):\n",
    "        for i in range(1,y+1):\n",
    "            path = f\"D:\\\\Data Science\\\\Python\\\\Signature Verification\\\\Training Data\\\\Test\\\\00{j}_{i}.png\"\n",
    "            fn = ntpath.basename(path)\n",
    "            tn = j\n",
    "            TestFilename.append(fn)\n",
    "            TestPerson.append(tn)\n",
    "            image = cv2.imread(path,0)\n",
    "            createfingerprint_Test(image)\n",
    "            Test_Signature_Table=pandas.DataFrame(Testdata)\n",
    "            Test_Cosine = pandas.DataFrame(cosine_similarity(Test_Signature_Table), index = None)\n",
    "            \n",
    "            \n",
    "\n",
    "    Test_Signature_Table['Filename'] = TestFilename\n",
    "    Test_Cosine['Filename'] = TestFilename\n",
    "    Trainingdatacol = Test_Signature_Table.columns.tolist()\n",
    "    Trainingdatacol = Trainingdatacol[-1:]+Trainingdatacol[:-1]\n",
    "    Test_Signature_Table = Test_Signature_Table[Trainingdatacol]\n",
    "    Test_Signature_Table['Person'] = TestPerson\n",
    "    Trainingdatacol = Test_Signature_Table.columns.tolist()\n",
    "    Trainingdatacol = Trainingdatacol[-1:]+Trainingdatacol[:-1]\n",
    "    Test_Signature_Table = Test_Signature_Table[Trainingdatacol]\n",
    "    Test_Signature_Table['Category'] = \"Test\"\n",
    "    Cosinecolumns = Test_Cosine.columns.tolist()\n",
    "    Cosinecolumns = Cosinecolumns[-1:]+Cosinecolumns[:-1]\n",
    "    Test_Cosine = Test_Cosine[Cosinecolumns]\n",
    "    #Original_Signature_Table = pandas.concat([Original_Signature_Table,Cosine],axis = 1)\n",
    "    Test_Signature_Table.to_csv('Test.csv', index = False)\n",
    "    Test_Cosine.to_csv('Cosine_Test.csv', index = False)\n",
    "    Summary_Table = pandas.DataFrame(Test_Signature_Table.describe()).T\n",
    "    Summary_Table.to_csv('Test_Summary.csv', index = False)\n",
    "    Test_Signature_Table\n",
    "    Test_Cosine\n",
    "    print('Preprocessing of Test Data Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Genuinedir = 'D:\\Data Science\\Python\\Signature Verification\\Training Data\\Train_Genuine'\n",
    "create_training_Genuine_dataset(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testdir = 'D:\\Data Science\\Python\\Signature Verification\\Training Data\\Test'\n",
    "create_test_dataset(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(Genuinedir)\n",
    "Original_Signature_Table = pandas.read_csv(\"Training.csv\")\n",
    "Cosine_Training = pandas.read_csv(\"Cosine_Training.csv\")\n",
    "os.chdir(Testdir)\n",
    "Test_Signature_Table = pandas.read_csv(\"Test.csv\")\n",
    "Cosine_Test = pandas.read_csv(\"Cosine_Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_Signature_Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Signature_Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Original_Signature_Table.groupby('Person').describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean_Original_Signature = pandas.DataFrame(Original_Signature_Table.groupby('Person').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean_Test_Signature = pandas.DataFrame(Test_Signature_Table.groupby('Person').mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
